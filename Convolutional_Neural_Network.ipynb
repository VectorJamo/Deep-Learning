{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN41aaCKZRYxKnvPKS4jj5j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VectorJamo/Deep-Learning/blob/main/Convolutional_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gC2TGFrr_NUL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms # Use out of the box data such as the MNIST images\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert MNIST images into a 4D Tensor (no. of images, height, width and the color channels)\n",
        "transform = transforms.ToTensor()"
      ],
      "metadata": {
        "id": "TXUCHk29OZaH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data\n",
        "training_data = datasets.MNIST(root='/cnn_data', train=True, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdAphbmlPIJK",
        "outputId": "21c7059b-8174-48ba-fc03-0b1866ca4026"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /cnn_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:10<00:00, 904kB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /cnn_data/MNIST/raw/train-images-idx3-ubyte.gz to /cnn_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /cnn_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 134kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /cnn_data/MNIST/raw/train-labels-idx1-ubyte.gz to /cnn_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /cnn_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.26MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /cnn_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /cnn_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /cnn_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /cnn_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /cnn_data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing data\n",
        "testing_data = datasets.MNIST(root='/cnn_data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "yTHTusdLP_e6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD5QWa64QIEt",
        "outputId": "931a64d2-a7a5-486b-ddda-95158fc743c9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: /cnn_data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwPB0S1SQMix",
        "outputId": "44a62b56-157a-4029-8198-83f9f880401b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: /cnn_data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create small batches of images\n",
        "batch_size = 10\n",
        "train_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(testing_data, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "VFVx2FAHQ-8x"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define our CNN Model\n",
        "# Describle the convolutional layer (2 convolutional layers)\n",
        "conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1) # no. of channels(color data) in the input image (1), use 6 distinct filters each of size 3x3, stride is 1\n",
        "conv2 = nn.Conv2d(6, 16, 3, 1) # no. of channels = 6, since the previous convolution layer outputs 6 volumes given by 6 distinct filters, use 16 distinct filters each of size 3x3, stride is 1"
      ],
      "metadata": {
        "id": "cXDMB2a1Sm06"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab 1 MNIST image\n",
        "for i, (X_train, y_train) in enumerate(training_data):\n",
        "  break"
      ],
      "metadata": {
        "id": "Q6rlFxWmXGCr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape # 1 image of size 28x28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzRCn3HMXsHj",
        "outputId": "14d192a5-847a-4243-99d8-7b2e46bc6814"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train # Value represented by that image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiE3-hccXvVd",
        "outputId": "9e8a7d5d-ad2e-4494-e76d-b20fd22b5c3b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = X_train.view(1, 1, 28, 28) # Reshape the X_train tensor in a new shape. 1 batch(1 image), 1 channel(black and white) of size 28x28"
      ],
      "metadata": {
        "id": "g52AZpCjYBbc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform our first convolution\n",
        "x = F.relu(conv1(x)) # Use relu as the activation function"
      ],
      "metadata": {
        "id": "ta7JBiLCYdVm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape # output of that 1 image after applying each of the 6 filters, which is 6 distinct 26x26 images."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNta1f63YzIj",
        "outputId": "212e6f64-644a-4bf6-dbf0-6a8a25f3a531"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 26, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass through the pooling layer\n",
        "x = F.max_pool2d(x, kernel_size=2, stride=2) # \"Compress\" the output of each of the 6 filters by applying a max pooling method."
      ],
      "metadata": {
        "id": "WHysZgG2Y1It"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eBU73fCZv2D",
        "outputId": "3cb71080-edcd-45c7-9107-62c9d3812fbd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 13, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do the second convolution layer\n",
        "x = F.relu(conv2(x))"
      ],
      "metadata": {
        "id": "Wbu_uGAVZwzd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfZU-AndaD6E",
        "outputId": "2f2aa865-aff1-43b4-aa62-30c19896ce29"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 11, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pooling layer\n",
        "x = F.max_pool2d(x, kernel_size=2, stride=2)"
      ],
      "metadata": {
        "id": "uKq07sgsatWd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6X6OG4Xa7Xk",
        "outputId": "532eb604-0d3a-4580-decf-14e8f11399c3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Condense everything we did above into a Model class\n",
        "class ConvolutionalNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3, stride=1)\n",
        "\n",
        "    # Fully connected layer\n",
        "    self.fc1 = nn.Linear(in_features=16*5*5, out_features=120) # Input features are the each individual data obtained after convolution and pooling.\n",
        "                                                               # In our case, the final result after pooling (for 1 image) was 16 \"compressed\" images of size 5x5\n",
        "                                                               # Output features is 120 which is open to tweaking.\n",
        "\n",
        "    self.fc2 = nn.Linear(in_features=120, out_features=84)     # Output features is 84 which is open to tweaking.\n",
        "    self.fc3 = nn.Linear(in_features=84, out_features=10)      # Output features for the final output layer is 10 since we have 10 digits to recognize.\n",
        "\n",
        "  def forward(self, X):\n",
        "    # Define how the input data will flow through the CNN\n",
        "\n",
        "    # First convolution\n",
        "    X = F.relu(self.conv1(X))\n",
        "    # First pooling\n",
        "    X = F.max_pool2d(X, kernel_size=2, stride=2)\n",
        "    # Second convolution\n",
        "    X = F.relu(self.conv2(X))\n",
        "    # Second pooling\n",
        "    X = F.max_pool2d(X, kernel_size=2, stride=2)\n",
        "\n",
        "    # Flatten this multidimension tensor into a 1D tensor so that we can pass it into the fully connected neural network layers\n",
        "    X = X.view(-1, 16*5*5) # -1 so that we can vary the batch size.\n",
        "\n",
        "    # Pass through the fully connected layers\n",
        "    X =  F.relu(self.fc1(X))\n",
        "    X =  F.relu(self.fc2(X))\n",
        "    X = self.fc3(X)\n",
        "\n",
        "    return F.log_softmax(X, dim=1)"
      ],
      "metadata": {
        "id": "aO27ts9Fa79z"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the model\n",
        "torch.manual_seed(41)\n",
        "model = ConvolutionalNetwork()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKL8OBTEiAEE",
        "outputId": "498d5bef-eed0-48b1-82b0-19e9b6ac7a52"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvolutionalNetwork(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "izufsR-liIuc"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# Create variables to track things\n",
        "epochs = 5\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_correct = []\n",
        "test_correct = []\n",
        "\n",
        "# For loop of epochs\n",
        "for i in range(epochs):\n",
        "  train_corr = 0\n",
        "  test_corr = 0\n",
        "\n",
        "  # Train\n",
        "  for b, (X_train, y_train) in enumerate(train_loader):\n",
        "    b += 1 # Start our batches at 1\n",
        "\n",
        "    # Apply our model\n",
        "    y_pred = model(X_train) # Run the model\n",
        "    loss = criterion(y_pred, y_train) # Calculate the loss. Compare the prediction to the actual label.\n",
        "\n",
        "    predicted = torch.max(y_pred.data, 1)[1] # Returns the maximum values and their indices. Get the index of the class with the highest probability score.\n",
        "    batch_corr = (predicted == y_train).sum() # Calculate the number of correct predictions\n",
        "    train_corr += batch_corr\n",
        "\n",
        "    # Update our parameters\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print out some results/progress\n",
        "    if b % 600 == 0:\n",
        "      print(f'Epoch: {i} Batch: {b} Loss: {loss.item()}')\n",
        "\n",
        "  train_losses.append(loss)\n",
        "  train_correct.append(train_corr)\n",
        "\n",
        "  # Test\n",
        "  with torch.no_grad():\n",
        "    for b, (X_test, y_test) in enumerate(test_loader):\n",
        "      y_val = model(X_test)\n",
        "      predicted = torch.max(y_val.data, 1)[1]\n",
        "      test_corr += (predicted == y_test).sum()\n",
        "\n",
        "    loss = criterion(y_val, y_test)\n",
        "    test_losses.append(loss)\n",
        "    test_correct.append(test_corr)\n",
        "\n",
        "current_time = time.time()\n",
        "time_taken = current_time - start_time\n",
        "print(f'Training took: {time_taken/60.0} minutes!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp-2Dthqix7U",
        "outputId": "b964d5cd-8d6f-46e8-de8d-cf661a347579"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Batch: 600 Loss: 0.2649766802787781\n",
            "Epoch: 0 Batch: 1200 Loss: 0.017863785848021507\n",
            "Epoch: 0 Batch: 1800 Loss: 0.006464975420385599\n",
            "Epoch: 0 Batch: 2400 Loss: 0.036078017204999924\n",
            "Epoch: 0 Batch: 3000 Loss: 0.10666809231042862\n",
            "Epoch: 0 Batch: 3600 Loss: 0.020617660135030746\n",
            "Epoch: 0 Batch: 4200 Loss: 0.01998436637222767\n",
            "Epoch: 0 Batch: 4800 Loss: 0.00944086629897356\n",
            "Epoch: 0 Batch: 5400 Loss: 0.015996595844626427\n",
            "Epoch: 0 Batch: 6000 Loss: 0.41673699021339417\n",
            "Epoch: 1 Batch: 600 Loss: 0.04192870110273361\n",
            "Epoch: 1 Batch: 1200 Loss: 0.43111753463745117\n",
            "Epoch: 1 Batch: 1800 Loss: 0.005686578806489706\n",
            "Epoch: 1 Batch: 2400 Loss: 0.005317699629813433\n",
            "Epoch: 1 Batch: 3000 Loss: 0.003176052588969469\n",
            "Epoch: 1 Batch: 3600 Loss: 0.0012339743552729487\n",
            "Epoch: 1 Batch: 4200 Loss: 0.01875397562980652\n",
            "Epoch: 1 Batch: 4800 Loss: 0.0004435688315425068\n",
            "Epoch: 1 Batch: 5400 Loss: 0.016413195058703423\n",
            "Epoch: 1 Batch: 6000 Loss: 0.030590971931815147\n",
            "Epoch: 2 Batch: 600 Loss: 0.019589880481362343\n",
            "Epoch: 2 Batch: 1200 Loss: 0.14533528685569763\n",
            "Epoch: 2 Batch: 1800 Loss: 0.2752438485622406\n",
            "Epoch: 2 Batch: 2400 Loss: 2.7583180781221017e-05\n",
            "Epoch: 2 Batch: 3000 Loss: 0.010952086187899113\n",
            "Epoch: 2 Batch: 3600 Loss: 0.0014680848689749837\n",
            "Epoch: 2 Batch: 4200 Loss: 0.00010059835767606273\n",
            "Epoch: 2 Batch: 4800 Loss: 0.0031551464926451445\n",
            "Epoch: 2 Batch: 5400 Loss: 0.19014650583267212\n",
            "Epoch: 2 Batch: 6000 Loss: 0.00010635425860527903\n",
            "Epoch: 3 Batch: 600 Loss: 0.0006583431386388838\n",
            "Epoch: 3 Batch: 1200 Loss: 0.00016004865756258368\n",
            "Epoch: 3 Batch: 1800 Loss: 0.0002109399065375328\n",
            "Epoch: 3 Batch: 2400 Loss: 0.371016263961792\n",
            "Epoch: 3 Batch: 3000 Loss: 0.00034712982596829534\n",
            "Epoch: 3 Batch: 3600 Loss: 9.813353244680911e-05\n",
            "Epoch: 3 Batch: 4200 Loss: 3.51511625922285e-05\n",
            "Epoch: 3 Batch: 4800 Loss: 0.0004427616368047893\n",
            "Epoch: 3 Batch: 5400 Loss: 0.000345263397321105\n",
            "Epoch: 3 Batch: 6000 Loss: 0.0007773563265800476\n",
            "Epoch: 4 Batch: 600 Loss: 1.8834016373148188e-05\n",
            "Epoch: 4 Batch: 1200 Loss: 0.32113054394721985\n",
            "Epoch: 4 Batch: 1800 Loss: 0.0004996731295250356\n",
            "Epoch: 4 Batch: 2400 Loss: 0.0007879970362409949\n",
            "Epoch: 4 Batch: 3000 Loss: 0.0006282309186644852\n",
            "Epoch: 4 Batch: 3600 Loss: 0.06632335484027863\n",
            "Epoch: 4 Batch: 4200 Loss: 0.017915425822138786\n",
            "Epoch: 4 Batch: 4800 Loss: 2.7583737391978502e-05\n",
            "Epoch: 4 Batch: 5400 Loss: 0.48095184564590454\n",
            "Epoch: 4 Batch: 6000 Loss: 1.2258117198944092\n",
            "Training took: 2.957133773962657 minutes!\n"
          ]
        }
      ]
    }
  ]
}